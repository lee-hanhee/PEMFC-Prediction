{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ea370c",
   "metadata": {},
   "source": [
    "# PyTorch Pressure Drop Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002dfdf",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226c5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustments: Implementing hyperparameter optimization\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class DelpNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple neural network for regression with five fully connected layers and dropout regularization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the neural network components.\n",
    "        \"\"\"\n",
    "        super(DelpNN, self).__init__()  # Initialize the superclass\n",
    "        # Define the layers of the neural network\n",
    "        self.fc1 = nn.Linear(6, 256)  # First fully connected layer with 6 inputs and 256 outputs\n",
    "        self.fc2 = nn.Linear(256, 128)  # Second fully connected layer with 256 inputs and 128 outputs\n",
    "        self.fc3 = nn.Linear(128, 64)    # Third fully connected layer with 128 inputs and 64 outputs\n",
    "        self.fc4 = nn.Linear(64, 16)    # Fourth fully connected layer with 64 inputs and 16 outputs\n",
    "        self.fc5 = nn.Linear(16, 1)    # Fifth fully connected layer with 16 inputs and 1 output (regression)\n",
    "        self.relu = nn.ReLU()  # Activation function used between layers\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer with a dropout probability of 0.5\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the neural network.\n",
    "        \"\"\"\n",
    "        x = self.relu(self.fc1(x))  # Pass input through the first layer and apply ReLU activation\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.relu(self.fc2(x))  # Pass through the second layer and apply ReLU activation\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.relu(self.fc3(x))  # Pass through the third layer and apply ReLU activation\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.relu(self.fc4(x))  # Pass through the fourth layer and apply ReLU activation\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc5(x)  # Output layer produces final output, no activation (linear output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0994e",
   "metadata": {},
   "source": [
    "## Load and Prepare Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6526760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_prepare_data(filepath):\n",
    "    \"\"\"\n",
    "    Load data from a file for training a machine learning model and convert it into tensors without scaling.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the data file. This file should be a whitespace-delimited text file and\n",
    "                        can contain comments starting with '%'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two elements:\n",
    "            - X_tensor (Tensor): Tensor containing the raw features.\n",
    "            - Y_tensor (Tensor): Tensor containing the raw target variable.\n",
    "            Returns (None, None) if an error occurs during file loading or data processing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the file, ignoring lines with '%', which are comments.\n",
    "        data = pd.read_csv(filepath, delim_whitespace=True, comment='%', header=None)\n",
    "        \n",
    "        # Set custom column names for ease of access\n",
    "        data.columns = ['HCC', 'WCC', 'LCC', 'Tamb', 'Uin', 'Q',\n",
    "                        'Temperature1', 'Temperature2', 'Temperature3', 'Temperature4',\n",
    "                        'Temperature5', 'Temperature6', 'Pressure1', 'Pressure2', 'Delp',\n",
    "                        'Velocity1', 'Velocity2', 'Tsta', 'StackTemp2']\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the data file: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Select specific columns for features and target\n",
    "    feature_labels = ['HCC', 'WCC', 'LCC', 'Tamb', 'Uin', 'Q']\n",
    "    X = data[feature_labels]\n",
    "    Y = data['Delp']\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ab6e77",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "808b2215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(X, Y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e6c10",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5264bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def preprocess_and_prepare_loaders(X_train, X_test, Y_train, Y_test, batch_size=64):\n",
    "    scaler_X = StandardScaler()\n",
    "\n",
    "    # Scale training data\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    \n",
    "    # Scale testing data using the same scaler\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    # Save the scaler for potential inverse transformations later\n",
    "    joblib.dump(scaler_X, '6_scaler_X.pkl')\n",
    "\n",
    "    # Convert scaled data to tensors. Use .values to correctly extract numpy arrays from pandas structures.\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Ensure that Y_train and Y_test, if they are pandas Series, are converted to tensors properly.\n",
    "    Y_train_tensor = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "    Y_test_tensor = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1)   # Use .values to extract the numpy array\n",
    "\n",
    "    # Create TensorDataset and DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Print samples of scaled data for verification\n",
    "    print(\"Scaled Training Features Sample:\")\n",
    "    print(X_train_tensor[:5])\n",
    "    print(\"Training Targets Sample:\")\n",
    "    print(Y_train_tensor[:5])\n",
    "    print(\"Scaled Testing Features Sample:\")\n",
    "    print(X_test_tensor[:5])\n",
    "    print(\"Testing Targets Sample:\")\n",
    "    print(Y_test_tensor[:5])\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7558712",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc4036e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "import os\n",
    "\n",
    "def train_model(config, checkpoint_dir=None, data_dir=None):\n",
    "    model = DelpNN()\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"lr\"],\n",
    "        betas=(config[\"beta1\"], config[\"beta2\"]),\n",
    "        eps=1e-08,\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "    )\n",
    "    \n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(os.path.join(checkpoint_dir, \"checkpoint.pt\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    train_loader, test_loader = data_dir\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = sum(criterion(model(inputs), labels).item() for inputs, labels in test_loader) / len(test_loader)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                path = os.path.join(checkpoint_dir, \"checkpoint.pt\")\n",
    "                torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= config[\"patience\"]:\n",
    "                print(f'Early stopping after {epoch+1} epochs')\n",
    "                break\n",
    "\n",
    "        tune.report(loss=val_loss)\n",
    "    \n",
    "    print('Training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9bd6d3",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c6069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, filename='true_vs_predicted.png'):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a trained neural network model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model.\n",
    "        test_loader (DataLoader): DataLoader for the test data.\n",
    "        criterion (torch.nn.MSELoss): Loss function to use for evaluating the model.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode.\n",
    "    total_loss = 0\n",
    "    total_rmse = 0\n",
    "    predictions, actuals = [], []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)  # Compute model output\n",
    "\n",
    "            # Calculate loss for the batch directly with tensors\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Convert tensors to numpy for calculating RMSE and plotting\n",
    "            outputs_np = outputs.detach().cpu().numpy()\n",
    "            labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "            # Calculate RMSE for each batch\n",
    "            rmse = mean_squared_error(labels_np, outputs_np, squared=False)\n",
    "            total_rmse += rmse * labels.size(0)\n",
    "\n",
    "            # Store predictions and actuals for plotting\n",
    "            predictions.extend(outputs_np.flatten())\n",
    "            actuals.extend(labels_np.flatten())\n",
    "\n",
    "    # Compute the average loss and RMSE\n",
    "    mean_loss = total_loss / len(test_loader.dataset)\n",
    "    mean_rmse = total_rmse / len(test_loader.dataset)\n",
    "    relative_error = (mean_rmse / np.mean(actuals)) * 100  # Calculate relative error as a percentage\n",
    "    r2 = r2_score(actuals, predictions)  # Calculate R^2 score\n",
    "\n",
    "    # Print calculated metrics\n",
    "    print(f'Test MSE: {mean_loss:.4f}')\n",
    "    print(f'Test RMSE: {mean_rmse:.4f} Pa')\n",
    "    print(f'Relative Error: {relative_error:.2f}%')\n",
    "    print(f'R^2 Score: {r2:.4f}')  # Print R^2 score\n",
    "\n",
    "    # Plot true vs predicted values\n",
    "    rcParams['font.family'] = 'serif'\n",
    "    rcParams['font.serif'] = ['Times New Roman']\n",
    "    rcParams['font.size'] = 12\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(actuals, predictions, alpha=0.5)\n",
    "    plt.plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], 'k-', label='Ideal Line')\n",
    "    plt.xlabel('True Pressure Drop')\n",
    "    plt.ylabel('Predicted Pressure Drop')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the figure as a PNG file\n",
    "    plt.savefig(filename, format='png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return mean_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc7725",
   "metadata": {},
   "source": [
    "## Predict New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b73380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_data_point(data_point, model_path, scaler_path):\n",
    "    # Load the trained model\n",
    "    model = DelpNN()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Load the scaler\n",
    "    scaler_X = joblib.load(scaler_path)\n",
    "\n",
    "    # Scale the single data point\n",
    "    data_point_scaled = scaler_X.transform([data_point])  # Note: [data_point] makes it 2D\n",
    "\n",
    "    # Convert to tensor\n",
    "    data_point_tensor = torch.tensor(data_point_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():  # No need to track gradients for predictions\n",
    "        output = model(data_point_tensor)\n",
    "\n",
    "    prediction = output.numpy()  # Convert to numpy array if necessary\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71baed0",
   "metadata": {},
   "source": [
    "## Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6e43fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 17:26:32,812\tINFO worker.py:1788 -- Started a local Ray instance.\n",
      "/var/folders/73/wzyp1fs57lg7p28crz696s_r0000gp/T/ipykernel_71372/85108997.py:19: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(filepath, delim_whitespace=True, comment='%', header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample X (features):\n",
      "     HCC     WCC   LCC    Tamb  Uin       Q\n",
      "0  0.001  0.0005  0.03  253.15  1.0  1272.0\n",
      "1  0.001  0.0005  0.03  273.15  1.0  1272.0\n",
      "2  0.001  0.0005  0.03  293.15  1.0  1272.0\n",
      "3  0.001  0.0005  0.03  313.15  1.0  1272.0\n",
      "4  0.001  0.0005  0.03  253.15  1.0  3132.0\n",
      "5  0.001  0.0005  0.03  273.15  1.0  3132.0\n",
      "6  0.001  0.0005  0.03  293.15  1.0  3132.0\n",
      "7  0.001  0.0005  0.03  313.15  1.0  3132.0\n",
      "8  0.001  0.0005  0.03  253.15  1.0  5040.0\n",
      "9  0.001  0.0005  0.03  273.15  1.0  5040.0\n",
      "Sample Y (targets):\n",
      "0     86.117\n",
      "1     89.914\n",
      "2     93.532\n",
      "3     96.944\n",
      "4     92.271\n",
      "5     96.889\n",
      "6    101.240\n",
      "7    105.300\n",
      "8     99.193\n",
      "9    104.310\n",
      "Name: Delp, dtype: float64\n",
      "Sample of training features:\n",
      "          HCC      WCC   LCC    Tamb    Uin       Q\n",
      "3281  0.00200  0.00100  0.09  273.15   7.75  3132.0\n",
      "2383  0.00175  0.00100  0.09  313.15   7.75  3132.0\n",
      "2009  0.00175  0.00050  0.06  273.15   5.50  3132.0\n",
      "2114  0.00175  0.00075  0.03  293.15   3.25  1272.0\n",
      "1128  0.00125  0.00125  0.06  253.15  10.00  1272.0\n",
      "Sample of training targets:\n",
      "3281    558.80\n",
      "2383    657.43\n",
      "2009    771.34\n",
      "2114    123.37\n",
      "1128    706.56\n",
      "Name: Delp, dtype: float64\n",
      "Sample of testing features:\n",
      "          HCC      WCC   LCC    Tamb   Uin       Q\n",
      "1340  0.00125  0.00150  0.09  253.15  3.25  5040.0\n",
      "1601  0.00150  0.00100  0.03  273.15  7.75  3132.0\n",
      "3549  0.00200  0.00150  0.06  273.15  1.00  5040.0\n",
      "3575  0.00200  0.00150  0.06  313.15  5.50  5040.0\n",
      "211   0.00100  0.00075  0.06  313.15  5.50  3132.0\n",
      "Sample of testing targets:\n",
      "1340    232.630\n",
      "1601    300.750\n",
      "3549     23.905\n",
      "3575    170.950\n",
      "211     826.650\n",
      "Name: Delp, dtype: float64\n",
      "Scaled Training Features Sample:\n",
      "tensor([[ 1.3061, -0.0454,  1.4041, -0.4449,  0.7213, -0.0181],\n",
      "        [ 0.5974, -0.0454,  1.4041,  1.3434,  0.7213, -0.0181],\n",
      "        [ 0.5974, -1.5239,  0.1541, -0.4449,  0.0138, -0.0181],\n",
      "        [ 0.5974, -0.7847, -1.0959,  0.4493, -0.6938, -1.2290],\n",
      "        [-0.8199,  0.6938,  0.1541, -1.3391,  1.4288, -1.2290]])\n",
      "Training Targets Sample:\n",
      "tensor([[558.8000],\n",
      "        [657.4300],\n",
      "        [771.3400],\n",
      "        [123.3700],\n",
      "        [706.5600]])\n",
      "Scaled Testing Features Sample:\n",
      "tensor([[-0.8199,  1.4330,  1.4041, -1.3391, -0.6938,  1.2242],\n",
      "        [-0.1112, -0.0454, -1.0959, -0.4449,  0.7213, -0.0181],\n",
      "        [ 1.3061,  1.4330,  0.1541, -0.4449, -1.4013,  1.2242],\n",
      "        [ 1.3061,  1.4330,  0.1541,  1.3434,  0.0138,  1.2242],\n",
      "        [-1.5285, -0.7847,  0.1541,  1.3434,  0.0138, -0.0181]])\n",
      "Testing Targets Sample:\n",
      "tensor([[232.6300],\n",
      "        [300.7500],\n",
      "        [ 23.9050],\n",
      "        [170.9500],\n",
      "        [826.6500]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 17:26:34,922\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2024-07-22 17:26:34,940\tWARNING bayesopt_search.py:431 -- BayesOpt does not support specific sampling methods. The LogUniform sampler will be dropped.\n",
      "2024-07-22 17:26:34,941\tWARNING bayesopt_search.py:431 -- BayesOpt does not support specific sampling methods. The LogUniform sampler will be dropped.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "BayesOpt does not support parameters of type `Categorical`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     78\u001b[0m ray\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m---> 79\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Execute the main function if the script is run directly.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 46\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m bayesopt \u001b[38;5;241m=\u001b[39m BayesOptSearch()\n\u001b[1;32m     44\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m ASHAScheduler(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_alg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbayesopt\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters found were: \u001b[39m\u001b[38;5;124m\"\u001b[39m, analysis\u001b[38;5;241m.\u001b[39mbest_config)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Load the best model checkpoint\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/fuel-cell-AI/00_PyTorch/myvenv/lib/python3.11/site-packages/ray/tune/tune.py:831\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(search_alg, Searcher):\n\u001b[1;32m    829\u001b[0m     search_alg \u001b[38;5;241m=\u001b[39m SearchGenerator(search_alg)\n\u001b[0;32m--> 831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43msearcher_set_search_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_alg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_search_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexperiments\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublic_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _has_unresolved_values(config):\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed a `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message_map[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_space_arg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` parameter to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message_map[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentrypoint\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem in the search algorithm\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms search space if necessary.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    846\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/Projects/fuel-cell-AI/00_PyTorch/myvenv/lib/python3.11/site-packages/ray/tune/search/util.py:19\u001b[0m, in \u001b[0;36m_set_search_properties_backwards_compatible\u001b[0;34m(set_search_properties_func, metric, mode, config, **spec)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wraps around set_search_properties() so that it is backward compatible.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mAlso outputs a warning to encourage custom searchers to be updated.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mset_search_properties_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_search_properties() got an unexpected keyword argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     ):\n",
      "File \u001b[0;32m~/Desktop/Projects/fuel-cell-AI/00_PyTorch/myvenv/lib/python3.11/site-packages/ray/tune/search/search_generator.py:62\u001b[0m, in \u001b[0;36mSearchGenerator.set_search_properties\u001b[0;34m(self, metric, mode, config, **spec)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_search_properties\u001b[39m(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m, metric: Optional[\u001b[38;5;28mstr\u001b[39m], mode: Optional[\u001b[38;5;28mstr\u001b[39m], config: Dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspec\n\u001b[1;32m     61\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_set_search_properties_backwards_compatible\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_search_properties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mspec\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/fuel-cell-AI/00_PyTorch/myvenv/lib/python3.11/site-packages/ray/tune/search/util.py:19\u001b[0m, in \u001b[0;36m_set_search_properties_backwards_compatible\u001b[0;34m(set_search_properties_func, metric, mode, config, **spec)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wraps around set_search_properties() so that it is backward compatible.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mAlso outputs a warning to encourage custom searchers to be updated.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mset_search_properties_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_search_properties() got an unexpected keyword argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     ):\n",
      "File \u001b[0;32m~/Desktop/Projects/fuel-cell-AI/00_PyTorch/myvenv/lib/python3.11/site-packages/ray/tune/search/bayesopt/bayesopt_search.py:235\u001b[0m, in \u001b[0;36mBayesOptSearch.set_search_properties\u001b[0;34m(self, metric, mode, config, **spec)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_search_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space \u001b[38;5;241m=\u001b[39m space\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric:\n",
      "File \u001b[0;32m~/Desktop/Projects/fuel-cell-AI/00_PyTorch/myvenv/lib/python3.11/site-packages/ray/tune/search/bayesopt/bayesopt_search.py:443\u001b[0m, in \u001b[0;36mBayesOptSearch.convert_search_space\u001b[0;34m(spec, join)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesOpt does not support parameters of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(domain)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    440\u001b[0m     )\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# Parameter name is e.g. \"a/b/c\" for nested dicts\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m bounds \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdomain_vars\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m join:\n\u001b[1;32m    446\u001b[0m     spec\u001b[38;5;241m.\u001b[39mupdate(bounds)\n",
      "File \u001b[0;32m~/Desktop/Projects/fuel-cell-AI/00_PyTorch/myvenv/lib/python3.11/site-packages/ray/tune/search/bayesopt/bayesopt_search.py:443\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesOpt does not support parameters of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(domain)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    440\u001b[0m     )\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# Parameter name is e.g. \"a/b/c\" for nested dicts\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m bounds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(path): \u001b[43mresolve_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path, domain \u001b[38;5;129;01min\u001b[39;00m domain_vars}\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m join:\n\u001b[1;32m    446\u001b[0m     spec\u001b[38;5;241m.\u001b[39mupdate(bounds)\n",
      "File \u001b[0;32m~/Desktop/Projects/fuel-cell-AI/00_PyTorch/myvenv/lib/python3.11/site-packages/ray/tune/search/bayesopt/bayesopt_search.py:437\u001b[0m, in \u001b[0;36mBayesOptSearch.convert_search_space.<locals>.resolve_value\u001b[0;34m(domain)\u001b[0m\n\u001b[1;32m    431\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    432\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesOpt does not support specific sampling methods. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    433\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sampler will be dropped.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(sampler)\n\u001b[1;32m    434\u001b[0m         )\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (domain\u001b[38;5;241m.\u001b[39mlower, domain\u001b[38;5;241m.\u001b[39mupper)\n\u001b[0;32m--> 437\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesOpt does not support parameters of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(domain)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    440\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: BayesOpt does not support parameters of type `Categorical`"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Main function to run the training and evaluation process.\n",
    "    filepath = '/Users/hanheelee/Desktop/Projects/00_ML_Fuel_Cell/Set 1.txt'  # Path to data file\n",
    "    X, Y = load_and_prepare_data(filepath)\n",
    "    if X is None or Y is None:\n",
    "        print(\"Failed to load data.\")\n",
    "        return\n",
    "    \n",
    "    # Print samples for verification\n",
    "    print(\"Sample X (features):\")\n",
    "    print(X[:10])\n",
    "    print(\"Sample Y (targets):\")\n",
    "    print(Y[:10])\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, Y_train, Y_test = split_data(X,Y)\n",
    "    \n",
    "    # Print samples for verification\n",
    "    print(\"Sample of training features:\")\n",
    "    print(X_train.head())\n",
    "    print(\"Sample of training targets:\")\n",
    "    print(Y_train.head())\n",
    "    print(\"Sample of testing features:\")\n",
    "    print(X_test.head())\n",
    "    print(\"Sample of testing targets:\")\n",
    "    print(Y_test.head())\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader, test_loader = preprocess_and_prepare_loaders(X_train, X_test, Y_train, Y_test)\n",
    "    \n",
    "    data_dir = (train_loader, test_loader)\n",
    "\n",
    "    search_space = {\n",
    "        \"lr\": tune.loguniform(1e-5, 1e-3),\n",
    "        \"beta1\": tune.uniform(0.5, 0.9),\n",
    "        \"beta2\": tune.uniform(0.9, 0.999),\n",
    "        \"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
    "        \"num_epochs\": tune.choice([50, 100, 200]),\n",
    "        \"patience\": tune.choice([5, 10, 20])\n",
    "    }\n",
    "\n",
    "    \n",
    "    bayesopt = BayesOptSearch()\n",
    "    scheduler = ASHAScheduler(metric=\"loss\", mode=\"min\")\n",
    "\n",
    "    analysis = tune.run(\n",
    "        tune.with_parameters(train_model, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": 0},\n",
    "        config=search_space,\n",
    "        num_samples=10,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=bayesopt\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "    \n",
    "    # Load the best model checkpoint\n",
    "    best_trial = analysis.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(best_checkpoint_dir, \"checkpoint.pt\"))\n",
    "\n",
    "    # Create a new model instance and load the state\n",
    "    best_model = DelpNN()\n",
    "    best_model.load_state_dict(model_state)\n",
    "\n",
    "    # Evaluate the best model\n",
    "    mean_rmse = evaluate_model(best_model, test_loader, nn.L1Loss())\n",
    "\n",
    "    # Save the best model's state dictionary\n",
    "    filename = f'Delp_{mean_rmse:.4f}.pth'\n",
    "    torch.save(best_model.state_dict(), filename)\n",
    "    \n",
    "    print(\"Model and scalers are saved successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(42)\n",
    "    ray.init()\n",
    "    main()  # Execute the main function if the script is run directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac65beb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchkernel",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
